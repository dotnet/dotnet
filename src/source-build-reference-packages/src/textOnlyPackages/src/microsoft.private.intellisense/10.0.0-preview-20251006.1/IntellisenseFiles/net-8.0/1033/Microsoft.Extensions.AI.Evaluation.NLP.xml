<?xml version="1.0" encoding="utf-8"?>
<doc>
  <assembly>
    <name>Microsoft.Extensions.AI.Evaluation.NLP</name>
  </assembly>
  <members>
    <member name="T:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that evaluates the quality of a response produced by an AI model by comparing
            it to a reference response using the BLEU (Bilingual Evaluation Understudy) algorithm. It is often used
            to evaluate the quality of machine translation or text generation tasks.</summary>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluator.#ctor" />
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> that should be used if one or
more composed <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>s use an AI model to perform evaluation.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluator.BLEUMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluator" />.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext">
      <summary>
            Contextual information that the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluator" /> uses to compute the BLEU score for a response.</summary>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext.#ctor(System.Collections.Generic.IEnumerable{System.String})">
      <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext" /> class.</summary>
      <param name="references">
            The reference responses against which the response that is being evaluated is compared.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext.#ctor(System.String[])">
      <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext" /> class.</summary>
      <param name="references">
            The reference responses against which the response that is being evaluated is compared.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext.References">
      <summary>
            Gets the references against which the provided response will be scored.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext.ReferencesContextName">
      <summary>
            Gets the unique <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationContext.Name" /> that is used for
            <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.BLEUEvaluatorContext" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.NLP.F1Evaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that evaluates the quality of a response produced by an AI model by comparing
            it to a reference response using the F1 scoring algorithm. F1 score is the ratio of the number of shared
            words between the generated response and the reference response.</summary>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.F1Evaluator.#ctor" />
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.F1Evaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> that should be used if one or
more composed <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>s use an AI model to perform evaluation.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.F1Evaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.F1Evaluator.F1MetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.F1Evaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.NLP.F1EvaluatorContext">
      <summary>
            Contextual information that the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.F1Evaluator" /> uses to compute the F1 score for a response.</summary>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.F1EvaluatorContext.#ctor(System.String)">
      <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.F1EvaluatorContext" /> class.</summary>
      <param name="groundTruth">
            The reference response against which the provided response will be scored.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.F1EvaluatorContext.GroundTruth">
      <summary>
            Gets the reference response against which the provided response will be scored.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.F1EvaluatorContext.GroundTruthContextName">
      <summary>
            Gets the unique <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationContext.Name" /> that is used for
            <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.F1EvaluatorContext" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluator">
      <summary>
            An <see cref="T:Microsoft.Extensions.AI.Evaluation.IEvaluator" /> that evaluates the quality of a response produced by an AI model by comparing
            it to a reference response using the GLEU (Google-BLEU) algorithm. The GLEU evaluator measures the similarity
            between the generated response and one or more reference responses using n-gram overlap.</summary>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluator.#ctor" />
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluator.EvaluateAsync(System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.ChatMessage},Microsoft.Extensions.AI.ChatResponse,Microsoft.Extensions.AI.Evaluation.ChatConfiguration,System.Collections.Generic.IEnumerable{Microsoft.Extensions.AI.Evaluation.EvaluationContext},System.Threading.CancellationToken)">
      <summary>Evaluates the supplied <code data-dev-comment-type="paramref">modelResponse</code> and returns an <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref>
containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</summary>
      <param name="messages">The conversation history including the request that produced the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="modelResponse">The response that is to be evaluated.</param>
      <param name="chatConfiguration">A <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.ChatConfiguration"></xref> that specifies the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.IChatClient"></xref> that should be used if one or
more composed <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>s use an AI model to perform evaluation.</param>
      <param name="additionalContext">Additional contextual information (beyond that which is available in <code data-dev-comment-type="paramref">messages</code>) that the
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref> may need to accurately evaluate the supplied <code data-dev-comment-type="paramref">modelResponse</code>.</param>
      <param name="cancellationToken">A <xref data-throw-if-not-resolved="true" uid="System.Threading.CancellationToken"></xref> that can cancel the evaluation operation.</param>
      <returns>An <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationResult"></xref> containing one or more <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s.</returns>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluator.EvaluationMetricNames">
      <summary>Gets the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name"></xref>s of the <xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.EvaluationMetric"></xref>s produced by this
<xref data-throw-if-not-resolved="true" uid="Microsoft.Extensions.AI.Evaluation.IEvaluator"></xref>.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluator.GLEUMetricName">
      <summary>
            Gets the <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationMetric.Name" /> of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NumericMetric" /> returned by
            <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluator" />.</summary>
    </member>
    <member name="T:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext">
      <summary>
            Contextual information that the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluator" /> uses to compute the GLEU score for a response.</summary>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext.#ctor(System.Collections.Generic.IEnumerable{System.String})">
      <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext" /> class.</summary>
      <param name="references">
            The reference responses against which the response that is being evaluated is compared.</param>
    </member>
    <member name="M:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext.#ctor(System.String[])">
      <summary>
            Initializes a new instance of the <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext" /> class.</summary>
      <param name="references">
            The reference responses against which the response that is being evaluated is compared.</param>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext.References">
      <summary>
            Gets the references against which the provided response will be scored.</summary>
    </member>
    <member name="P:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext.ReferencesContextName">
      <summary>
            Gets the unique <see cref="P:Microsoft.Extensions.AI.Evaluation.EvaluationContext.Name" /> that is used for
            <see cref="T:Microsoft.Extensions.AI.Evaluation.NLP.GLEUEvaluatorContext" />.</summary>
    </member>
  </members>
</doc>